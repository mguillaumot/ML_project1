{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "import numpy as np\n",
    "from proj1_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from costs import compute_mse, compute_loss\n",
    "# from plots import *\n",
    "from helpers import *\n",
    "# from grid_search import *\n",
    "# import datetime\n",
    "# from ridge_regression import *\n",
    "# from gradient_descent import *\n",
    "# from stochastic_gradient_descent import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_TRAIN = '../data/train.csv'\n",
    "y_train, data_train, ids_tr = load_csv_data(DATA_PATH_TRAIN, sub_sample=False)\n",
    "# y_train, data_train, ids_tr = load_csv_data(DATA_PATH_TRAIN, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_TEST = '../data/test.csv'\n",
    "_, data_test, ids_te = load_csv_data(DATA_PATH_TEST, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features standardized for subset : 0\n",
      "Features standardized for subset : 1\n",
      "Features standardized for subset : 2\n"
     ]
    }
   ],
   "source": [
    "datasets_train, datasets_test = preprocess_datasets(data_train, data_test, y_train = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Least Square Gradient Descent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, method, max_iters = 0, gamma = 0, lambda_ = 0):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "\n",
    "    # get k'th subgroup in test, others in train\n",
    "    ind_train = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    ind_test = k_indices[k]\n",
    "    ind_train = ind_train.reshape(-1)\n",
    "    \n",
    "    x_train = x[ind_train]\n",
    "    y_train = y[ind_train]\n",
    "    x_test = x[ind_test]\n",
    "    y_test = y[ind_test]\n",
    "    \n",
    "    # form data  -- TODO: Change for augmented features\n",
    "    poly_train = x_train\n",
    "    poly_test = x_test\n",
    "\n",
    "    if method == least_squares_GD or method == least_squares_SGD or method == logistic_regression:\n",
    "        initial_w = np.zeros([poly_train.shape[1]])\n",
    "        w, loss = method(y = y_train, tx = poly_train, initial_w = initial_w, max_iters = max_iters, gamma = gamma)\n",
    "        \n",
    "    elif method == least_squares:\n",
    "        w, loss = method(y = y_train, tx = poly_train)\n",
    "        \n",
    "    elif method == ridge_regression:\n",
    "        w, loss = method(y = y_train, tx = poly_train, lambda_ = lambda_)\n",
    "        \n",
    "    elif method == reg_logistic_regression:\n",
    "        initial_w = np.zeros([poly_train.shape[1]])\n",
    "        w, loss = method(y = y_train, tx = poly_train, lambda_ = lambda_, initial_w = initial_w, max_iters = max_iters, gamma = gamma)\n",
    "    \n",
    "    # Compute prediction for train and test\n",
    "    y_pred_train = predict_labels(w, poly_train)\n",
    "    y_pred_test = predict_labels(w, poly_test)\n",
    "    \n",
    "    loss_tr = 2 * np.sqrt(2 * compute_loss(y_train, poly_train, w))\n",
    "    loss_te = 2 * np.sqrt(2 * compute_loss(y_test, poly_test, w))\n",
    "#     print(\" --- y = -1 :: Reel: {} :: Prediction: {}\".format( (y_train == -1).sum(), (y_pred_train == -1).sum() )) \n",
    "#     print(\" --- y = +1 :: Reel: {} :: Prediction: {}\".format( (y_train == 1).sum(), (y_pred_train == 1).sum() )) \n",
    "    \n",
    "    # Compute accuracy for train and test \n",
    "    accuracy_train = compute_accuracy(y_pred_train, y_train)\n",
    "    accuracy_test = compute_accuracy(y_pred_test, y_test)\n",
    "    \n",
    "    \n",
    "    return accuracy_train, accuracy_test, w, loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " For case jet = 0 \n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 1e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.7428737288814157\n",
      "Variance test accuracy: 0.0066308483540856175\n",
      "Min test accuracy: 0.7286412042597485\n",
      "Max test accuracy: 0.7525822723997118\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 2.2758459260747865e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.7445552085835536\n",
      "Variance test accuracy: 0.0039154271709591765\n",
      "Min test accuracy: 0.7388101529345824\n",
      "Max test accuracy: 0.752902554247738\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 5.1794746792312125e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.741572583873809\n",
      "Variance test accuracy: 0.01325764725198929\n",
      "Min test accuracy: 0.7096645047641925\n",
      "Max test accuracy: 0.7570662182720794\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.00011787686347935866 :: gamma = 0.7\n",
      "Average test accuracy: 0.7422832092241172\n",
      "Variance test accuracy: 0.009613620057195205\n",
      "Min test accuracy: 0.7183121146609016\n",
      "Max test accuracy: 0.752902554247738\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.0002682695795279727 :: gamma = 0.7\n",
      "Average test accuracy: 0.7406517735607334\n",
      "Variance test accuracy: 0.00784986650794381\n",
      "Min test accuracy: 0.7296821202658339\n",
      "Max test accuracy: 0.752902554247738\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.0006105402296585327 :: gamma = 0.7\n",
      "Average test accuracy: 0.6904375850748659\n",
      "Variance test accuracy: 0.16466324761990872\n",
      "Min test accuracy: 0.257426535351109\n",
      "Max test accuracy: 0.7988629994395068\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.0013894954943731374 :: gamma = 0.7\n",
      "Average test accuracy: 0.7492593482264392\n",
      "Variance test accuracy: 0.021851352311709843\n",
      "Min test accuracy: 0.7280006405636961\n",
      "Max test accuracy: 0.804708143165986\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.0031622776601683794 :: gamma = 0.7\n",
      "Average test accuracy: 0.7382196332772839\n",
      "Variance test accuracy: 0.013926100590776877\n",
      "Min test accuracy: 0.704219713347746\n",
      "Max test accuracy: 0.7528224837857315\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.0071968567300115215 :: gamma = 0.7\n",
      "Average test accuracy: 0.7432540635759468\n",
      "Variance test accuracy: 0.005532834161681103\n",
      "Min test accuracy: 0.7351269116822804\n",
      "Max test accuracy: 0.752902554247738\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.016378937069540647 :: gamma = 0.7\n",
      "Average test accuracy: 0.7377892545439988\n",
      "Variance test accuracy: 0.020415406573755523\n",
      "Min test accuracy: 0.6846825206181439\n",
      "Max test accuracy: 0.752902554247738\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.037275937203149416 :: gamma = 0.7\n",
      "Average test accuracy: 0.7510509248138362\n",
      "Variance test accuracy: 0.017291671747338925\n",
      "Min test accuracy: 0.7388101529345824\n",
      "Max test accuracy: 0.7948594763391785\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.08483428982440726 :: gamma = 0.7\n",
      "Average test accuracy: 0.7422732004163665\n",
      "Variance test accuracy: 0.008503482122648306\n",
      "Min test accuracy: 0.7218352149891905\n",
      "Max test accuracy: 0.752342061013692\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.19306977288832497 :: gamma = 0.7\n",
      "Average test accuracy: 0.7441648650812716\n",
      "Variance test accuracy: 0.004375108495525185\n",
      "Min test accuracy: 0.7388101529345824\n",
      "Max test accuracy: 0.752902554247738\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 0.4393970560760795 :: gamma = 0.7\n",
      "Average test accuracy: 0.7406817999839859\n",
      "Variance test accuracy: 0.007072077941667758\n",
      "Min test accuracy: 0.7243974697734006\n",
      "Max test accuracy: 0.7467371286732325\n",
      "\n",
      "\n",
      "SUBSET 0 --- lambda_ = 1.0 :: gamma = 0.7\n",
      "Average test accuracy: 0.744304988389783\n",
      "Variance test accuracy: 0.0037513540193397322\n",
      "Min test accuracy: 0.7388101529345824\n",
      "Max test accuracy: 0.7519417087036592\n",
      "\n",
      "\n",
      "\n",
      " For case jet = 1 \n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 1e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.46524553801712576\n",
      "Variance test accuracy: 0.13687110802368674\n",
      "Min test accuracy: 0.34674507376457236\n",
      "Max test accuracy: 0.6511915815536985\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 2.2758459260747865e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.5387392963994635\n",
      "Variance test accuracy: 0.13680342855724628\n",
      "Min test accuracy: 0.35149076653254924\n",
      "Max test accuracy: 0.6541834313422057\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 5.1794746792312125e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.5611007943877024\n",
      "Variance test accuracy: 0.11983241458683544\n",
      "Min test accuracy: 0.35097493036211697\n",
      "Max test accuracy: 0.6532549262354276\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.00011787686347935866 :: gamma = 0.7\n",
      "Average test accuracy: 0.5642473950273393\n",
      "Variance test accuracy: 0.11337813536337937\n",
      "Min test accuracy: 0.3592283090890333\n",
      "Max test accuracy: 0.6541834313422057\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.0002682695795279727 :: gamma = 0.7\n",
      "Average test accuracy: 0.6129681213246674\n",
      "Variance test accuracy: 0.058032623762440984\n",
      "Min test accuracy: 0.46518105849582175\n",
      "Max test accuracy: 0.6536675951717734\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.0006105402296585327 :: gamma = 0.7\n",
      "Average test accuracy: 0.5723718147116476\n",
      "Variance test accuracy: 0.12300953622481524\n",
      "Min test accuracy: 0.3592283090890333\n",
      "Max test accuracy: 0.6541834313422057\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.0013894954943731374 :: gamma = 0.7\n",
      "Average test accuracy: 0.5365469926751264\n",
      "Variance test accuracy: 0.13774716778516502\n",
      "Min test accuracy: 0.3458165686577943\n",
      "Max test accuracy: 0.649025069637883\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.0031622776601683794 :: gamma = 0.7\n",
      "Average test accuracy: 0.6411327762302692\n",
      "Variance test accuracy: 0.008206660046008759\n",
      "Min test accuracy: 0.6283916228205921\n",
      "Max test accuracy: 0.6533580934695141\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.0071968567300115215 :: gamma = 0.7\n",
      "Average test accuracy: 0.6101568141958114\n",
      "Variance test accuracy: 0.0848354452129475\n",
      "Min test accuracy: 0.38646445888785724\n",
      "Max test accuracy: 0.6541834313422057\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.016378937069540647 :: gamma = 0.7\n",
      "Average test accuracy: 0.5701021355617456\n",
      "Variance test accuracy: 0.12260715038141197\n",
      "Min test accuracy: 0.35685546270504487\n",
      "Max test accuracy: 0.6541834313422057\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.037275937203149416 :: gamma = 0.7\n",
      "Average test accuracy: 0.4989425358506139\n",
      "Variance test accuracy: 0.14276822346735935\n",
      "Min test accuracy: 0.3458165686577943\n",
      "Max test accuracy: 0.6431445372949551\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.08483428982440726 :: gamma = 0.7\n",
      "Average test accuracy: 0.5718301867326938\n",
      "Variance test accuracy: 0.12338434315748324\n",
      "Min test accuracy: 0.35685546270504487\n",
      "Max test accuracy: 0.6539770968740328\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.19306977288832497 :: gamma = 0.7\n",
      "Average test accuracy: 0.6029608996182813\n",
      "Variance test accuracy: 0.09531618188953632\n",
      "Min test accuracy: 0.35107809759620345\n",
      "Max test accuracy: 0.6431445372949551\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 0.4393970560760795 :: gamma = 0.7\n",
      "Average test accuracy: 0.6381796141545446\n",
      "Variance test accuracy: 0.010401032470092712\n",
      "Min test accuracy: 0.6193129062209842\n",
      "Max test accuracy: 0.6541834313422057\n",
      "\n",
      "\n",
      "SUBSET 1 --- lambda_ = 1.0 :: gamma = 0.7\n",
      "Average test accuracy: 0.5415634994325802\n",
      "Variance test accuracy: 0.11783391798187712\n",
      "Min test accuracy: 0.3707830393067162\n",
      "Max test accuracy: 0.6537707624058599\n",
      "\n",
      "\n",
      "\n",
      " For case jet = 2 \n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 1e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.5319289731995147\n",
      "Variance test accuracy: 0.076378755132966\n",
      "Min test accuracy: 0.43939561045549796\n",
      "Max test accuracy: 0.6401235248704091\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 2.2758459260747865e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.568531487812948\n",
      "Variance test accuracy: 0.06938889548619118\n",
      "Min test accuracy: 0.45130693724495424\n",
      "Max test accuracy: 0.6566670343002096\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 5.1794746792312125e-05 :: gamma = 0.7\n",
      "Average test accuracy: 0.5530219477225102\n",
      "Variance test accuracy: 0.05730433161381322\n",
      "Min test accuracy: 0.4487702657990515\n",
      "Max test accuracy: 0.6706738722841072\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.00011787686347935866 :: gamma = 0.7\n",
      "Average test accuracy: 0.5549520238226536\n",
      "Variance test accuracy: 0.08367779734685685\n",
      "Min test accuracy: 0.44369692290724605\n",
      "Max test accuracy: 0.67817359655895\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.0002682695795279727 :: gamma = 0.7\n",
      "Average test accuracy: 0.5333903165324805\n",
      "Variance test accuracy: 0.07033468813188722\n",
      "Min test accuracy: 0.44799823535899413\n",
      "Max test accuracy: 0.6664828498952244\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.0006105402296585327 :: gamma = 0.7\n",
      "Average test accuracy: 0.5801119444138083\n",
      "Variance test accuracy: 0.08844987033001436\n",
      "Min test accuracy: 0.4515275173706849\n",
      "Max test accuracy: 0.6749751847358553\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.0013894954943731374 :: gamma = 0.7\n",
      "Average test accuracy: 0.5329353700231609\n",
      "Variance test accuracy: 0.08997593243409077\n",
      "Min test accuracy: 0.44226315208999667\n",
      "Max test accuracy: 0.6717767729127606\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUBSET 2 --- lambda_ = 0.0031622776601683794 :: gamma = 0.7\n",
      "Average test accuracy: 0.4890537112606154\n",
      "Variance test accuracy: 0.08895961449520427\n",
      "Min test accuracy: 0.3625234366383589\n",
      "Max test accuracy: 0.6702327120326459\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.0071968567300115215 :: gamma = 0.7\n",
      "Average test accuracy: 0.6065953457593471\n",
      "Variance test accuracy: 0.06564790752819066\n",
      "Min test accuracy: 0.4468953347303408\n",
      "Max test accuracy: 0.6733208337928752\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.016378937069540647 :: gamma = 0.7\n",
      "Average test accuracy: 0.49692566449762876\n",
      "Variance test accuracy: 0.07250539818466127\n",
      "Min test accuracy: 0.44336605271865004\n",
      "Max test accuracy: 0.6654902393294364\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.037275937203149416 :: gamma = 0.7\n",
      "Average test accuracy: 0.5060659534575935\n",
      "Variance test accuracy: 0.04766409999296237\n",
      "Min test accuracy: 0.44799823535899413\n",
      "Max test accuracy: 0.5577368479100033\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.08483428982440726 :: gamma = 0.7\n",
      "Average test accuracy: 0.5376916289842285\n",
      "Variance test accuracy: 0.07751204037755695\n",
      "Min test accuracy: 0.4487702657990515\n",
      "Max test accuracy: 0.6593139958089776\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.19306977288832497 :: gamma = 0.7\n",
      "Average test accuracy: 0.5451499944854968\n",
      "Variance test accuracy: 0.07810351892906339\n",
      "Min test accuracy: 0.44899084592478217\n",
      "Max test accuracy: 0.6674754604610125\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 0.4393970560760795 :: gamma = 0.7\n",
      "Average test accuracy: 0.5137862578581669\n",
      "Variance test accuracy: 0.09606152095543956\n",
      "Min test accuracy: 0.4013455387669571\n",
      "Max test accuracy: 0.6714459027241646\n",
      "\n",
      "\n",
      "SUBSET 2 --- lambda_ = 1.0 :: gamma = 0.7\n",
      "Average test accuracy: 0.5390426822543288\n",
      "Variance test accuracy: 0.08113732675086241\n",
      "Min test accuracy: 0.4503143266791662\n",
      "Max test accuracy: 0.6731002536671445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from plots import cross_validation_visualization\n",
    "\n",
    "# Model parameters\n",
    "method = logistic_regression\n",
    "\n",
    "max_iters = 150\n",
    "seed = 1\n",
    "k_fold = 8\n",
    "lambdas = np.logspace(-5, 0, 15)\n",
    "# lambdas = []\n",
    "# lambdas.append(1)\n",
    "# gammas = np.arange(0.5, 0.7, 0.1)\n",
    "gamma = 0.7\n",
    "\n",
    "y_pred_final = np.zeros((len(ids_te),1))\n",
    "\n",
    "# For each case (jet = 0, jet = 1, jet = 2,3)\n",
    "for ind, subset_train in enumerate(datasets_train):\n",
    "    print(\"\\n\\n For case jet = {} \\n\".format(ind))\n",
    "    x = subset_train[0]\n",
    "    y = subset_train[1]\n",
    "    \n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "    # define lists to store the accuracy of training data and test data\n",
    "    accuracy_train = []\n",
    "    accuracy_test = []\n",
    "\n",
    "#     for gamma in gammas:\n",
    "    \n",
    "    accuracy_train_lambda = []\n",
    "    accuracy_test_lambda = []\n",
    "\n",
    "    rmse_train_lambda = []\n",
    "    rmse_test_lambda = []\n",
    "\n",
    "    for lambda_ in lambdas:\n",
    "        param_method = dict(max_iters = max_iters, gamma = gamma, lambda_ = lambda_)\n",
    "\n",
    "        accuracy_train_k = []\n",
    "        accuracy_test_k = []\n",
    "        rmse_train_k = []\n",
    "        rmse_test_k = []\n",
    "        w_k = []\n",
    "        # cross validation  \n",
    "        for k in range(k_fold):\n",
    "            accuracy_train_crt, accuracy_test_crt, w, rmse_tr_crt, rmse_te_crt = cross_validation(y, x, k_indices, k, method = method, **param_method)\n",
    "            accuracy_train_k.append(accuracy_train_crt)\n",
    "            accuracy_test_k.append(accuracy_test_crt)\n",
    "            rmse_train_k.append(rmse_tr_crt)\n",
    "            rmse_test_k.append(rmse_te_crt)\n",
    "            w_k.append(w)\n",
    "#                 print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (k, accuracy_train_crt, accuracy_test_crt))\n",
    "\n",
    "        print(\"\\nSUBSET {} --- lambda_ = {} :: gamma = {}\".format(ind, lambda_, gamma))\n",
    "        print(\"Average test accuracy: {}\".format(np.mean(accuracy_test_k)))\n",
    "        print(\"Variance test accuracy: {}\".format(np.std(accuracy_test_k)))\n",
    "        print(\"Min test accuracy: {}\".format(np.min(accuracy_test_k)))\n",
    "        print(\"Max test accuracy: {}\\n\".format(np.max(accuracy_test_k)))   \n",
    "\n",
    "        accuracy_train_lambda.append(np.mean(accuracy_train_k))\n",
    "        accuracy_test_lambda.append(np.mean(accuracy_test_k))\n",
    "\n",
    "        rmse_train_lambda.append(np.mean(rmse_train_k))\n",
    "        rmse_test_lambda.append(np.mean(rmse_test_k))\n",
    "        \n",
    "\n",
    "#         fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6), sharey=True)\n",
    "#         axes[0].boxplot([rmse_train_lambda, rmse_test_lambda] , labels=['rmse_train_lambda', 'rmse_test_lambda'], notch=True, bootstrap=10000)\n",
    "#         cross_validation_visualization(lambdas, rmse_train_lambda, rmse_test_lambda)\n",
    "\n",
    "    accuracy_train.append(np.mean(accuracy_train_lambda))\n",
    "    accuracy_test.append(np.mean(accuracy_test_lambda))\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # ****************************************\n",
    "    # ****** Predict for datasets_test *******\n",
    "    # ****************************************\n",
    "    if test == True:\n",
    "        subset_test = datasets_test[ind][0]\n",
    "        poly_test = subset_test\n",
    "\n",
    "        y_pred_crt = predict_labels(w_k[0], poly_test)   # TODO : for now takes the first w\n",
    "        np.put(y_pred_final, datasets_test[ind][1], y_pred_crt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test == True:\n",
    "    if method == least_squares_GD:\n",
    "        create_csv_submission(ids_te, y_pred_final, '../least_squares_GD.csv')\n",
    "        \n",
    "    elif method == least_squares_SGD:\n",
    "        create_csv_submission(ids_te, y_pred_final, '../least_squares_SGD.csv')\n",
    "        \n",
    "    elif method == least_squares:\n",
    "        create_csv_submission(ids_te, y_pred_final, '../least_squares.csv')\n",
    "        \n",
    "    elif method == ridge_regression:\n",
    "        create_csv_submission(ids_te, y_pred_final, '../ridge_regression.csv')\n",
    "        \n",
    "    elif method == logistic_regression:\n",
    "        create_csv_submission(ids_te, y_pred_final, '../logistic_regression.csv')\n",
    "        \n",
    "    elif method == reg_logistic_regression:\n",
    "        create_csv_submission(ids_te, y_pred_final, '../reg_logistic_regression.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
